{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7e1ec6",
   "metadata": {},
   "source": [
    "\n",
    "<img alt=\"Mepylome Logo\" src=\"https://raw.githubusercontent.com/brj0/mepylome/main/mepylome/data/assets/mepylome.svg\" width=\"300\">\n",
    "\n",
    "Mepylome: A Toolkit for DNA-Methylation Analysis in Tumor Diagnostics\n",
    "=====================================================================\n",
    "\n",
    "This notebook automates the analysis outlined in the Mepylome publication,\n",
    "performing all necessary steps from downloading datasets to executing the\n",
    "analyses.\n",
    "\n",
    "\n",
    "### Usage\n",
    "\n",
    "- All datasets and outputs are saved in `~/mepylome`.\n",
    "- Follow the notebook/script step-by-step for an in-depth understanding of\n",
    "  the workflow and results.\n",
    "\n",
    "\n",
    "### System Requirements\n",
    "\n",
    "- *Operating System*: Ubuntu 20.04.6\n",
    "- *Python Version*: 3.12\n",
    "\n",
    "\n",
    "### Reference Publication (will follow)\n",
    "\n",
    "- *Title*: Mepylome: A User-Friendly Open-Source Toolkit for DNA-Methylation\n",
    "  Analysis in Tumor Diagnostics\n",
    "- *Author*: Jon Brugger et al.\n",
    "\n",
    "\n",
    "### Run This Notebook in Google Colab\n",
    "\n",
    "You can quickly open and run this notebook in Google Colab without any setup\n",
    "by clicking the link below.\n",
    "\n",
    "**Note**: The graphical user interface (GUI) features won't run in Colab, but\n",
    "the rest of the analysis will work as expected.\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/brj0/mepylome/blob/main/examples/publication_analysis.ipynb)\n",
    "\n",
    "\n",
    "This notebook was automatically generated from the corresponding py-file\n",
    "with:\n",
    "\n",
    "```bash\n",
    "jupytext --to ipynb publication_analysis.py\n",
    "```\n",
    "\n",
    "\n",
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354646c6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Contents\n",
    "0. **[Initialization](#0.-Initialization)**\n",
    "1. **[Salivary Gland Tumors](#1.-Salivary-Gland-Tumors)**\n",
    "2. **[Soft Tissue Tumors](#2.-Soft-Tissue-Tumors)**\n",
    "3. **[Squamous Cell Carcinoma](#3.-Squamous-Cell-Carcinoma)**\n",
    "4. **[Appendix](#4.-Appendix)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda482b",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "<a name=\"0.-Initialization\"></a>\n",
    "## 0. Initialization\n",
    "\n",
    "### Install Required Packages\n",
    "\n",
    "To run the analysis, install the following Python packages:\n",
    "- `mepylome` – the main toolkit for DNA-methylation analysis.\n",
    "- `linear_segment` – used for segmentation calculations in CNV plots.\n",
    "- `kaleido` for saving plots.\n",
    "\n",
    "Install these packages using the commands below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b572d5e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"Install necessary packages. This may take 1 to 2 minutes...\"\n",
    "\n",
    "pip install mepylome\n",
    "pip install ipython\n",
    "pip install pillow\n",
    "pip install linear_segment\n",
    "pip install -U kaleido\n",
    "\n",
    "echo\n",
    "echo \"Installation complete.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07c9b5",
   "metadata": {},
   "source": [
    "### Core Imports, Configuration and main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98adc3c9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import tarfile\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import Image as IPImage\n",
    "from PIL import Image\n",
    "\n",
    "from mepylome import ArrayType, Manifest\n",
    "from mepylome.analysis import MethylAnalysis\n",
    "from mepylome.dtypes.manifests import (\n",
    "    DOWNLOAD_DIR,\n",
    "    MANIFEST_URL,\n",
    "    REMOTE_FILENAME,\n",
    ")\n",
    "from mepylome.utils import ensure_directory_exists\n",
    "from mepylome.utils.files import (\n",
    "    download_file,\n",
    "    download_geo_probes,\n",
    ")\n",
    "\n",
    "# Define output font size for plots\n",
    "FONTSIZE = 23\n",
    "GEO_URL = \"https://www.ncbi.nlm.nih.gov/geo/download/?acc={acc}&format=file\"\n",
    "\n",
    "# Define dataset URLs and filenames\n",
    "datasets = {\n",
    "    \"salivary_gland_tumors\": {\n",
    "        \"xlsx\": \"https://ars.els-cdn.com/content/image/1-s2.0-S0893395224002059-mmc4.xlsx\",\n",
    "        \"geo_ids\": [\"GSE243075\"],\n",
    "    },\n",
    "    \"soft_tissue_tumors\": {\n",
    "        \"xlsx\": \"https://static-content.springer.com/esm/art%3A10.1038%2Fs41467-020-20603-4/MediaObjects/41467_2020_20603_MOESM4_ESM.xlsx\",\n",
    "        \"geo_ids\": [\"GSE140686\"],\n",
    "    },\n",
    "    \"sinonasal_tumors\": {\n",
    "        \"xlsx\": \"https://static-content.springer.com/esm/art%3A10.1038%2Fs41467-022-34815-3/MediaObjects/41467_2022_34815_MOESM6_ESM.xlsx\",\n",
    "        \"geo_ids\": [\"GSE196228\"],\n",
    "    },\n",
    "    \"scc\": {\n",
    "        \"xlsx\": \"https://www.science.org/doi/suppl/10.1126/scitranslmed.aaw8513/suppl_file/aaw8513_data_file_s1.xlsx\",\n",
    "        \"geo_ids\": [\"GSE85566\"],\n",
    "    },\n",
    "    \"scc_test\": {\n",
    "        \"geo_ids\": [\n",
    "            \"GSE124052\",\n",
    "            \"GSE66836\",\n",
    "            \"GSE79556\",\n",
    "            \"GSE87053\",\n",
    "            \"GSE95036\",\n",
    "            \"GSE124052\",\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Determine basic storage directory depending on platform\n",
    "if \"COLAB_GPU\" in os.environ:\n",
    "    # Google Colab\n",
    "    mepylome_dir = Path(\"/content/mepylome\")\n",
    "elif os.path.exists(\"/mnt/bender\"):\n",
    "    # Bender-specific path\n",
    "    mepylome_dir = Path(\"/mnt/bender/mepylome\")\n",
    "else:\n",
    "    # Default for local Linux or other environments\n",
    "    mepylome_dir = Path.home() / \"mepylome\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(mepylome_dir, exist_ok=True)\n",
    "os.environ[\"MEPYLOME_DIR\"] = str(mepylome_dir)\n",
    "print(f\"Data will be stored in: {mepylome_dir}\")\n",
    "\n",
    "data_dir = mepylome_dir / \"data\"\n",
    "output_dir = mepylome_dir / \"out\"\n",
    "reference_dir = mepylome_dir / \"cn_neutral_idats\"\n",
    "validation_dir = mepylome_dir / \"validation_data\"\n",
    "\n",
    "ensure_directory_exists(data_dir)\n",
    "ensure_directory_exists(output_dir)\n",
    "ensure_directory_exists(reference_dir)\n",
    "ensure_directory_exists(validation_dir)\n",
    "\n",
    "# Main Funktions\n",
    "\n",
    "\n",
    "def extract_tar(tar_path, output_directory):\n",
    "    \"\"\"Extracts tar file under 'tar_path' to 'output_directory'.\"\"\"\n",
    "    ensure_directory_exists(output_directory)\n",
    "    with tarfile.open(tar_path, \"r\") as tar:\n",
    "        tar.extractall(path=output_directory, filter=\"data\")\n",
    "        print(f\"Extracted {tar_path} to {output_directory}\")\n",
    "\n",
    "\n",
    "def download_from_geo_and_untar(analysis_dir, geo_ids):\n",
    "    \"\"\"Downloads all missing GEO files and untars them.\"\"\"\n",
    "    for geo_id in geo_ids:\n",
    "        idat_dir = analysis_dir / geo_id\n",
    "        if idat_dir.exists():\n",
    "            print(f\"Data for GEO ID {geo_id} already exists, skipping.\")\n",
    "            continue\n",
    "        try:\n",
    "            tar_path = analysis_dir / f\"{geo_id}.tar\"\n",
    "            geo_url = GEO_URL.format(acc=geo_id)\n",
    "            download_file(geo_url, tar_path)\n",
    "            extract_tar(tar_path, idat_dir)\n",
    "            tar_path.unlink()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing GEO ID {geo_id}: {e}\")\n",
    "\n",
    "\n",
    "def calculate_cn_summary(analysis, class_):\n",
    "    \"\"\"Calculates and saves CN summary plots.\"\"\"\n",
    "    df_class = analysis.idat_handler.samples_annotated[class_]\n",
    "    plot_list = []\n",
    "    analysis_dir = analysis.analysis_dir\n",
    "    all_classes = sorted(df_class.unique())\n",
    "    for methyl_class in all_classes:\n",
    "        df_index = df_class == methyl_class\n",
    "        sample_ids = df_class.index[df_index]\n",
    "        plot, df_cn_summary = analysis.cn_summary(sample_ids)\n",
    "        plot.update_layout(\n",
    "            title=f\"{methyl_class}\",\n",
    "            title_x=0.5,\n",
    "            yaxis_title=\"Proportion of CNV gains/losses\",\n",
    "        )\n",
    "        plot.update_layout(\n",
    "            title_font_size=FONTSIZE + 3,\n",
    "            yaxis_title_font_size=FONTSIZE - 2,\n",
    "        )\n",
    "        plot_list.append(plot)\n",
    "    png_paths = [\n",
    "        output_dir / f\"{analysis_dir.name}-cn_summary-{x}.png\"\n",
    "        for x in all_classes\n",
    "    ]\n",
    "    for path, fig in zip(png_paths, plot_list):\n",
    "        fig.write_image(path)\n",
    "    images = [Image.open(path) for path in png_paths]\n",
    "    width, height = images[0].size\n",
    "    n_columns = 4\n",
    "    n_images = len(images)\n",
    "    n_rows = (n_images + n_columns - 1) // n_columns\n",
    "    total_width = width * n_columns\n",
    "    total_height = height * n_rows\n",
    "    new_image = Image.new(\"RGB\", (total_width, total_height), (255, 255, 255))\n",
    "    for index, img in enumerate(images):\n",
    "        row = index // n_columns\n",
    "        col = index % n_columns\n",
    "        x = col * width\n",
    "        y = row * height\n",
    "        new_image.paste(img, (x, y))\n",
    "    output_path = output_dir / f\"{analysis_dir.name}-cn_summary.png\"\n",
    "    new_image.save(output_path)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c8f5e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Blacklist Generation for CpG Sites\n",
    "\n",
    "Some CpG sites should be excluded from the analysis. Here we choose probes\n",
    "flagged with `MFG_Change_Flagged` that should be excluded according to the\n",
    "manifest and those that are on sex chromosomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201e9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_blacklist_cpgs():\n",
    "    \"\"\"Returns and caches CpG sites that should be blacklisted.\"\"\"\n",
    "    print(\"Generating blacklist. Can take some time...\")\n",
    "    blacklist_path = data_dir / \"cpg_blacklist.csv\"\n",
    "    if not blacklist_path.exists():\n",
    "        manifest_url = MANIFEST_URL[ArrayType.ILLUMINA_EPIC]\n",
    "        ensure_directory_exists(DOWNLOAD_DIR)\n",
    "        response = requests.get(manifest_url)\n",
    "        html_sucess_ok_code = 200\n",
    "        if response.status_code == html_sucess_ok_code:\n",
    "            with zipfile.ZipFile(io.BytesIO(response.content)) as thezip:\n",
    "                thezip.extractall(DOWNLOAD_DIR)\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"Failed to download the file: {response.status_code}\"\n",
    "            )\n",
    "        csv_path = DOWNLOAD_DIR / REMOTE_FILENAME[ArrayType.ILLUMINA_EPIC]\n",
    "        manifest_df = pd.read_csv(csv_path, skiprows=7)\n",
    "        flagged_cpgs = manifest_df[\n",
    "            manifest_df[\"MFG_Change_Flagged\"].fillna(False)\n",
    "        ][\"IlmnID\"]\n",
    "        flagged_cpgs.to_csv(blacklist_path, index=False, header=False)\n",
    "        csv_path.unlink()\n",
    "    blacklist = pd.read_csv(blacklist_path, header=None)\n",
    "    print(\"Generating blacklist done.\")\n",
    "    return set(blacklist.iloc[:, 0])\n",
    "\n",
    "\n",
    "def sex_chromosome_cpgs():\n",
    "    \"\"\"Returns CpGs on sex chromosomes for EPIC and 450k arrays.\"\"\"\n",
    "    manifest = Manifest(\"epic\")\n",
    "    sex_cpgs_epic = manifest.data_frame[\n",
    "        manifest.data_frame.Chromosome.isin([23, 24])\n",
    "    ].IlmnID\n",
    "    manifest = Manifest(\"450k\")\n",
    "    sex_cpgs_450k = manifest.data_frame[\n",
    "        manifest.data_frame.Chromosome.isin([23, 24])\n",
    "    ].IlmnID\n",
    "    return set(sex_cpgs_epic) | set(sex_cpgs_450k)\n",
    "\n",
    "\n",
    "# Choose CpG list that should be blacklisted\n",
    "blacklist = generate_blacklist_cpgs() | sex_chromosome_cpgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26095b1a",
   "metadata": {},
   "source": [
    "### Copy-Neutral Reference Probes\n",
    "\n",
    "To ensure accurate analysis, we utilize control probes from the [Koelsche et\n",
    "al. (2021) study](https://doi.org/10.1038/s41467-020-20603-4). These probes\n",
    "are stored in the designated reference directory `reference_dir`.\n",
    "\n",
    "**Best Practices**:\n",
    "- Include both fresh-frozen and FFPE (formalin-fixed paraffin-embedded)\n",
    "  samples in the copy-neutral reference set for optimal results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa94ac",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "cn_neutral_probes = [\n",
    "    \"GSM4180453_201904410008_R06C01\",\n",
    "    \"GSM4180454_201904410008_R05C01\",\n",
    "    \"GSM4180455_201904410008_R04C01\",\n",
    "    \"GSM4180456_201904410008_R03C01\",\n",
    "    \"GSM4180457_201904410008_R02C01\",\n",
    "    \"GSM4180458_201904410008_R01C01\",\n",
    "    \"GSM4180459_201904410007_R08C01\",\n",
    "    \"GSM4180460_201904410007_R07C01\",\n",
    "    \"GSM4180741_201247480004_R05C01\",\n",
    "    \"GSM4180742_201247480004_R04C01\",\n",
    "    \"GSM4180743_201247480004_R03C01\",\n",
    "    \"GSM4180751_201194010006_R01C01\",\n",
    "    \"GSM4180909_200394870074_R04C02\",\n",
    "    \"GSM4180910_200394870074_R03C02\",\n",
    "    \"GSM4180911_200394870074_R02C02\",\n",
    "    \"GSM4180912_200394870074_R01C02\",\n",
    "    \"GSM4180913_200394870074_R05C01\",\n",
    "    \"GSM4180914_200394870074_R04C01\",\n",
    "    \"GSM4181456_203049640041_R03C01\",\n",
    "    \"GSM4181509_203049640040_R07C01\",\n",
    "    \"GSM4181510_203049640040_R08C01\",\n",
    "    \"GSM4181511_203049640041_R01C01\",\n",
    "    \"GSM4181512_203049640041_R02C01\",\n",
    "    \"GSM4181513_203049640041_R04C01\",\n",
    "    \"GSM4181514_203049640041_R05C01\",\n",
    "    \"GSM4181515_203049640041_R06C01\",\n",
    "    \"GSM4181516_203049640041_R07C01\",\n",
    "    \"GSM4181517_203049640041_R08C01\",\n",
    "]\n",
    "\n",
    "download_geo_probes(reference_dir, cn_neutral_probes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa1b3c",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "<a name=\"1.-Salivary-Gland-Tumors\"></a>\n",
    "## 1. Salivary Gland Tumors\n",
    "\n",
    "This section replicates the methylation analysis performed in the study by\n",
    "[Jurmeister et al. (2024)](https://doi.org/10.1016/j.modpat.2024.100625). To\n",
    "begin, we download the required data and organize it within the designated\n",
    "directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d3fcd0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Initialize directories.\n",
    "tumor_site = \"salivary_gland_tumors\"\n",
    "analysis_dir_sg = data_dir / tumor_site\n",
    "test_dir_sg = validation_dir / tumor_site\n",
    "\n",
    "ensure_directory_exists(test_dir_sg)\n",
    "ensure_directory_exists(analysis_dir_sg)\n",
    "\n",
    "# Download the the annotation spreadsheet.\n",
    "if not (\n",
    "    excel_path := analysis_dir_sg / f\"{tumor_site}-annotation.xlsx\"\n",
    ").exists():\n",
    "    download_file(datasets[tumor_site][\"xlsx\"], excel_path)\n",
    "    # Deletes the first 2 rows (useless description).\n",
    "    pd.read_excel(excel_path, skiprows=2).to_excel(excel_path, index=False)\n",
    "\n",
    "# Download the IDAT files.\n",
    "download_from_geo_and_untar(analysis_dir_sg, datasets[tumor_site][\"geo_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c1b1c",
   "metadata": {},
   "source": [
    "### Create the Methylation Analysis Object\n",
    "\n",
    "The `MethylAnalysis` object serves as the main interface for performing DNA\n",
    "methylation analysis. Key parameters such as the directory structure, number\n",
    "of CpG sites, and UMAP settings are configured here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b9889",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "analysis_sg = MethylAnalysis(\n",
    "    analysis_dir=analysis_dir_sg,\n",
    "    reference_dir=reference_dir,\n",
    "    output_dir=output_dir,\n",
    "    test_dir=test_dir_sg,\n",
    "    n_cpgs=25000,\n",
    "    load_full_betas=True,\n",
    "    overlap=False,\n",
    "    cpg_blacklist=blacklist,\n",
    "    debug=True,\n",
    "    do_seg=True,\n",
    "    umap_parms={\n",
    "        \"n_neighbors\": 8,\n",
    "        \"metric\": \"manhattan\",\n",
    "        \"min_dist\": 0.3,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd2199",
   "metadata": {},
   "source": [
    "### Load Beta Values\n",
    "\n",
    "Reads and processes beta values from the provided dataset. This step can also\n",
    "be performed interactively within the GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4025f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "analysis_sg.set_betas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a46e9",
   "metadata": {},
   "source": [
    "### Generate UMAP Plot\n",
    "\n",
    "Set the columns used for coloring the UMAP plot before initiating the\n",
    "dimensionality reduction process. The UMAP algorithm produces a visual\n",
    "representation of the sample clusters, which is stored as a Plotly object in\n",
    "`analysis_sg.umap_plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate UMAP\n",
    "analysis_sg.idat_handler.selected_columns = [\"Methylation class\"]\n",
    "analysis_sg.make_umap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b537c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results\n",
    "print(analysis_sg.umap_df)\n",
    "output_path = output_dir / f\"{analysis_dir_sg.name}-umap_plot.jpg\"\n",
    "analysis_sg.umap_plot.write_image(\n",
    "    output_path,\n",
    "    format=\"jpg\",\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    scale=2,\n",
    ")\n",
    "IPImage(filename=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e137c0e",
   "metadata": {},
   "source": [
    "### Launch the Analysis GUI\n",
    "\n",
    "Initializes an interactive GUI for further exploration of the methylation\n",
    "data.\n",
    "\n",
    "**Note**: This step is only supported in local environments (not in\n",
    "cloud-based platforms like Google Colab or Binder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf75d3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "analysis_sg.run_app(open_tab=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce2c40",
   "metadata": {},
   "source": [
    "### Generate and Save CNV Plot\n",
    "\n",
    "Creates a copy number variation (CNV) plot for a specified sample and saves\n",
    "the output as a high-resolution image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CNV example\n",
    "analysis_sg.make_cnv_plot(\"206842050057_R06C01\")\n",
    "cnv_plot = analysis_sg.cnv_plot\n",
    "cnv_plot.update_layout(\n",
    "    yaxis_range=[-1.1, 1.1],\n",
    "    font={\"size\": FONTSIZE},\n",
    "    margin={\"t\": 50},\n",
    ")\n",
    "output_path = output_dir / f\"{analysis_dir_sg.name}-cnv_plot.jpg\"\n",
    "cnv_plot.write_image(\n",
    "    output_path,\n",
    "    format=\"jpg\",\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    scale=2,\n",
    ")\n",
    "IPImage(filename=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f11ad",
   "metadata": {},
   "source": [
    "### Generate CNV Summary Plots\n",
    "\n",
    "In addition to individual CNV plots, this step computes summary plots to\n",
    "highlight genomic alterations across multiple samples.\n",
    "\n",
    "**Note**:\n",
    "Generating all copy number variation (CNV) plots can be resource-intensive.\n",
    "The process may take up to 30 minutes, depending on the computational\n",
    "resources available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c72bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_sg.precompute_cnvs()\n",
    "cn_summary_path_sg = calculate_cn_summary(analysis_sg, \"Methylation class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28796186",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPImage(filename=cn_summary_path_sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2492c",
   "metadata": {},
   "source": [
    "### Supervised Classifier Validation\n",
    "\n",
    "The next step involves validating various supervised classification\n",
    "algorithms to evaluate their performance on the dataset. This process helps\n",
    "identify the most accurate model for methylation-based classification.\n",
    "\n",
    "**Note**:\n",
    "Training can be resource-intensive. The process may take up to 10 minutes,\n",
    "depending on the computational resources available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b533fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train supervised classifiers\n",
    "ids = analysis_sg.idat_handler.ids\n",
    "clf_out_sg = analysis_sg.classify(\n",
    "    ids=ids,\n",
    "    clf_list=[\n",
    "        \"none-kbest-et\",\n",
    "        \"none-kbest-lr\",\n",
    "        \"none-kbest-rf\",\n",
    "        \"none-kbest-svc_rbf\",\n",
    "        \"none-pca-lr\",\n",
    "        \"none-pca-et\",\n",
    "        \"none-none-knn\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd30732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print reports for all classifier for the first sample\n",
    "for clf_result in clf_out_sg:\n",
    "    print(clf_result.reports[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14440c1b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Identify and display the best classifier\n",
    "best_clf_sg = max(\n",
    "    clf_out_sg, key=lambda result: np.mean(result.metrics[\"accuracy_scores\"])\n",
    ")\n",
    "print(\"Most accurate classifier:\")\n",
    "print(best_clf_sg.reports[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdfe9bc",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "<a name=\"2.-Soft-Tissue-Tumors\"></a>\n",
    "## 2. Soft Tissue Tumors\n",
    "\n",
    "This section replicates the methylation analysis performed in the study by\n",
    "[Koelsche2021 study](https://doi.org/10.1038/s41467-020-20603-4). To begin,\n",
    "we download the required data and organize it within the designated\n",
    "directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560581df",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Initialize directories.\n",
    "tumor_site = \"soft_tissue_tumors\"\n",
    "analysis_dir_sf = data_dir / tumor_site\n",
    "test_dir_sf = validation_dir / tumor_site\n",
    "\n",
    "ensure_directory_exists(test_dir_sf)\n",
    "ensure_directory_exists(analysis_dir_sf)\n",
    "\n",
    "# Download the the annotation spreadsheet.\n",
    "if not (\n",
    "    excel_path := analysis_dir_sf / f\"{tumor_site}-annotation.xlsx\"\n",
    ").exists():\n",
    "    download_file(datasets[tumor_site][\"xlsx\"], excel_path)\n",
    "\n",
    "# Download the IDAT files.\n",
    "download_from_geo_and_untar(analysis_dir_sf, datasets[tumor_site][\"geo_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31058de",
   "metadata": {},
   "source": [
    "### Create the Methylation Analysis Object\n",
    "\n",
    "The `MethylAnalysis` object serves as the main interface for performing DNA\n",
    "methylation analysis. Key parameters such as the directory structure, number\n",
    "of CpG sites, and UMAP settings are configured here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c4f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_sf = MethylAnalysis(\n",
    "    analysis_dir=analysis_dir_sf,\n",
    "    reference_dir=reference_dir,\n",
    "    output_dir=output_dir,\n",
    "    n_cpgs=25000,\n",
    "    load_full_betas=True,\n",
    "    overlap=False,\n",
    "    cpg_blacklist=blacklist,\n",
    "    debug=True,\n",
    "    do_seg=True,\n",
    "    umap_parms={\n",
    "        \"n_neighbors\": 8,\n",
    "        \"metric\": \"manhattan\",\n",
    "        \"min_dist\": 0.3,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bf4fa4",
   "metadata": {},
   "source": [
    "### Load Beta Values\n",
    "\n",
    "Reads and processes beta values from the provided dataset. This step can also\n",
    "be performed interactively within the GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7d125f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "analysis_sf.set_betas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57db734e",
   "metadata": {},
   "source": [
    "### Generate UMAP Plot\n",
    "\n",
    "Set the columns used for coloring the UMAP plot before initiating the\n",
    "dimensionality reduction process. The UMAP algorithm produces a visual\n",
    "representation of the sample clusters, which is stored as a Plotly object in\n",
    "`analysis_sf.umap_plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd01e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate UMAP\n",
    "analysis_sf.idat_handler.selected_columns = [\"Methylation Class Name\"]\n",
    "analysis_sf.make_umap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4bc8d2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Show the results\n",
    "print(analysis_sf.umap_df)\n",
    "output_path = output_dir / f\"{analysis_dir_sf.name}-umap_plot.jpg\"\n",
    "analysis_sf.umap_plot.write_image(\n",
    "    output_path,\n",
    "    format=\"jpg\",\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    scale=2,\n",
    ")\n",
    "IPImage(filename=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada57bd3",
   "metadata": {},
   "source": [
    "### Launch the Analysis GUI\n",
    "\n",
    "Initializes an interactive GUI for further exploration of the methylation\n",
    "data.\n",
    "\n",
    "**Note**: This step is only supported in local environments (not in\n",
    "cloud-based platforms like Google Colab or Binder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06725a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "analysis_sf.run_app(open_tab=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f355a86",
   "metadata": {},
   "source": [
    "### Generate and Save CNV Plot\n",
    "\n",
    "Creates a copy number variation (CNV) plot for a specified sample and saves\n",
    "the output as a high-resolution image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ceefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CNV example\n",
    "analysis_sf.make_cnv_plot(\"3999112131_R05C01\")\n",
    "cnv_plot = analysis_sf.cnv_plot\n",
    "cnv_plot.update_layout(\n",
    "    yaxis_range=[-1.1, 1.1],\n",
    "    font={\"size\": FONTSIZE},\n",
    "    margin={\"t\": 50},\n",
    ")\n",
    "output_path = output_dir / f\"{analysis_dir_sf.name}-cnv_plot.jpg\"\n",
    "cnv_plot.write_image(\n",
    "    output_path,\n",
    "    format=\"jpg\",\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    scale=2,\n",
    ")\n",
    "IPImage(filename=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d9b980",
   "metadata": {},
   "source": [
    "### Generate CNV Summary Plots\n",
    "\n",
    "In addition to individual CNV plots, this step computes summary plots to\n",
    "highlight genomic alterations across multiple samples.\n",
    "\n",
    "**Note**:\n",
    "Generating all copy number variation (CNV) plots can be resource-intensive.\n",
    "The process may take up to 30 minutes, depending on the computational\n",
    "resources available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c9f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_sf.precompute_cnvs()\n",
    "cn_summary_path_sf = calculate_cn_summary(analysis_sg, \"Methylation class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e811be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPImage(filename=cn_summary_path_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e43943e",
   "metadata": {},
   "source": [
    "### Supervised Classifier Validation\n",
    "\n",
    "The next step involves validating various supervised classification\n",
    "algorithms to evaluate their performance on the dataset. This process helps\n",
    "identify the most accurate model for methylation-based classification.\n",
    "\n",
    "**Note**:\n",
    "Training can be resource-intensive. The process may take up to 10 minutes,\n",
    "depending on the computational resources available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a01b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train supervised classifiers\n",
    "ids = analysis_sf.idat_handler.ids\n",
    "clf_out_sf = analysis_sf.classify(\n",
    "    ids=ids,\n",
    "    clf_list=[\n",
    "        \"none-kbest-et\",\n",
    "        \"none-kbest-lr\",\n",
    "        \"none-kbest-rf\",\n",
    "        \"none-kbest-svc_rbf\",\n",
    "        \"none-pca-lr\",\n",
    "        \"none-pca-et\",\n",
    "        \"none-none-knn\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a09bd9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Print reports for all classifier for the first sample\n",
    "for clf_result in clf_out_sf:\n",
    "    print(clf_result.reports[0])\n",
    "\n",
    "# Identify and display the best classifier\n",
    "best_clf_sf = max(\n",
    "    clf_out_sf, key=lambda result: np.mean(result.metrics[\"accuracy_scores\"])\n",
    ")\n",
    "print(\"Most accurate classifier:\")\n",
    "print(best_clf_sf.reports[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeb6ae7",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "<a name=\"3.-Squamous-Cell-Carcinoma\"></a>\n",
    "## 3. Squamous Cell Carcinoma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc14eff",
   "metadata": {},
   "source": [
    "In this example, we aim to reproduce the pan-SCC classifier presented in the\n",
    "study by [Jurmeister et al.\n",
    "(2019)](https://doi.org/10.1126/scitranslmed.aaw8513). Our goal is to gather\n",
    "data for Squamous Cell Carcinoma (SCC) from multiple sources, as outlined in\n",
    "the publication, including datasets from The Cancer Genome Atlas (TCGA).\n",
    "Datasets without IDAT files are omitted from the collection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349a08b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize directories.\n",
    "tumor_site = \"scc\"\n",
    "analysis_dir_scc = data_dir / tumor_site\n",
    "test_dir_scc = validation_dir / tumor_site\n",
    "\n",
    "ensure_directory_exists(test_dir_scc)\n",
    "ensure_directory_exists(analysis_dir_scc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91158bf7",
   "metadata": {},
   "source": [
    "### Step 1: Download TCGA Data\n",
    "First we download the GDC client that is used for downloading data from TCGA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0613f5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gdc_client_url = \"https://gdc.cancer.gov/system/files/public/file/gdc-client_2.3_Ubuntu_x64-py3.8-ubuntu-20.04.zip\"\n",
    "gdc_client_bin = analysis_dir_scc / \"gdc-client\"\n",
    "\n",
    "# Download and set up the GDC client\n",
    "if not gdc_client_bin.exists():\n",
    "    zip_path_0 = analysis_dir_scc / \"gdc-client.zip\"\n",
    "    zip_path_1 = analysis_dir_scc / \"gdc-client_2.3_Ubuntu_x64.zip\"\n",
    "    download_file(gdc_client_url, zip_path_0)\n",
    "    with zipfile.ZipFile(zip_path_0, \"r\") as zip_file:\n",
    "        zip_file.extractall(analysis_dir_scc)\n",
    "    with zipfile.ZipFile(zip_path_1, \"r\") as zip_file:\n",
    "        zip_file.extractall(analysis_dir_scc)\n",
    "    zip_path_0.unlink()\n",
    "    zip_path_1.unlink()\n",
    "    gdc_client_bin.chmod(0o755)\n",
    "    print(f\"GDC client binary downloaded and set up at {gdc_client_bin}\")\n",
    "else:\n",
    "    print(f\"GDC client already exists at {gdc_client_bin}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8325bcd9",
   "metadata": {},
   "source": [
    "Now we download the complete TCGA data. **This may take several hours** due\n",
    "to slow server connection speeds. It is recommended to run this process\n",
    "overnight and not to abort the process to ensure it completes successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6cfc90",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "tcga_dir = analysis_dir_scc / \"tcga_scc\"\n",
    "tcga_downloaded_tag = tcga_dir / \".download_complete\"\n",
    "tcga_anno_dir_tar = analysis_dir_scc / \"tcga_annotations.tar.gz\"\n",
    "tcga_anno_dir = tcga_anno_dir_tar.with_suffix(\"\").with_suffix(\"\")\n",
    "\n",
    "ensure_directory_exists(tcga_dir)\n",
    "\n",
    "# Check if the TCGA annotation tar file exists and extract\n",
    "if not tcga_anno_dir.exists():\n",
    "    print(\"Setting up TCGA annotation directory...\")\n",
    "    # TODO download annotation to tcga_anno_dir_tar\n",
    "    extract_tar(tcga_anno_dir_tar, analysis_dir_scc)\n",
    "    print(\"Setting up TCGA annotation directory done.\")\n",
    "\n",
    "# Check if the download is complete\n",
    "if not tcga_downloaded_tag.exists():\n",
    "    print(\"Download has not been completed yet.\")\n",
    "    if not gdc_client_bin.exists():\n",
    "        msg = f\"Error: GDC client not found at {gdc_client_bin}\"\n",
    "        raise FileNotFoundError(msg)\n",
    "    print(\"Downloading TCGA files. This may take some time!\")\n",
    "    manifest_file = next(tcga_anno_dir.glob(\"gdc_manifest.*txt\"))\n",
    "    if not manifest_file.exists():\n",
    "        msg = \"No TCGA manifest file found.\"\n",
    "        raise FileNotFoundError(msg)\n",
    "    print(f\"Downloading TCGA data from manifest file: {manifest_file}\")\n",
    "    subprocess.run(\n",
    "        [\n",
    "            str(gdc_client_bin),\n",
    "            \"download\",\n",
    "            \"--latest\",\n",
    "            \"--manifest\",\n",
    "            manifest_file,\n",
    "            \"--dir\",\n",
    "            str(tcga_dir),\n",
    "        ],\n",
    "        check=True,\n",
    "    )\n",
    "    print(\"Download finished.\")\n",
    "    tcga_downloaded_tag.touch()\n",
    "else:\n",
    "    print(\"TCGA data already completely downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb1e5b6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Clean up by moving all IDAT files into one directory and removing array types\n",
    "other than `450k` and `epic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6a89b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def move_idat_files_and_cleanup(root_dir):\n",
    "    \"\"\"Move all idat files one dir up and delete empty subdirectories.\"\"\"\n",
    "    root_dir = Path(root_dir)\n",
    "    for sub_dir in root_dir.iterdir():\n",
    "        if sub_dir.is_dir():\n",
    "            idat_files = list(sub_dir.glob(\"*.idat\"))\n",
    "            for file in idat_files:\n",
    "                destination = root_dir / file.name\n",
    "                shutil.move(str(file), str(destination))\n",
    "            shutil.rmtree(sub_dir)\n",
    "\n",
    "\n",
    "def remove_invalid_array_types(root_dir):\n",
    "    idat_files = root_dir.glob(\"*idat\")\n",
    "    valid_array_types = {ArrayType.ILLUMINA_450K, ArrayType.ILLUMINA_EPIC}\n",
    "    for idat_file in idat_files:\n",
    "        array_type = ArrayType.from_idat(idat_file)\n",
    "        if not array_type in valid_array_types:\n",
    "            print(f\"Removing {idat_file.name} (Type: {array_type})\")\n",
    "            idat_file.unlink()\n",
    "\n",
    "\n",
    "move_idat_files_and_cleanup(tcga_dir)\n",
    "remove_invalid_array_types(tcga_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743a83a5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Next we extract the TCGA annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb27cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tcga_case_id_dict(json_path):\n",
    "    \"\"\"Extracts a dictionary mapping from IDAT IDs to case IDs.\"\"\"\n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "    case_id_mapping = {}\n",
    "    n_suffix = len(\"_Grn.idat\")\n",
    "    for item in data:\n",
    "        file_name = item.get(\"file_name\", \"\")[:-n_suffix]\n",
    "        case_id = item.get(\"associated_entities\", [{}])[0].get(\"case_id\", \"\")\n",
    "        if case_id and file_name:\n",
    "            case_id_mapping[case_id] = file_name\n",
    "    return case_id_mapping\n",
    "\n",
    "\n",
    "json_metadata = next(tcga_anno_dir.glob(\"metadata.cart.*json\"))\n",
    "case_id_to_sample_id = extract_tcga_case_id_dict(json_metadata)\n",
    "\n",
    "# Load the clinical data and map the case_id to the IDAT\n",
    "tcga_annotation = pd.read_csv(tcga_anno_dir / \"clinical.tsv\", delimiter=\"\\t\")\n",
    "tcga_annotation[\"Sample_ID\"] = tcga_annotation[\"case_id\"].map(\n",
    "    case_id_to_sample_id\n",
    ")\n",
    "tcga_annotation = tcga_annotation.drop(columns=\"case_id\")\n",
    "\n",
    "# Rename columns\n",
    "columns_dict = {\n",
    "    \"gender\": \"Sex\",\n",
    "    \"age_at_index\": \"Age\",\n",
    "    \"tissue_or_organ_of_origin\": \"Tumor_site\",\n",
    "    \"site_of_resection_or_biopsy\": \"Site_of_resection_or_biopsy\",\n",
    "    \"tumor_grade\": \"Tumor_grade\",\n",
    "    \"morphology\": \"Morphology\",\n",
    "    \"primary_diagnosis\": \"Primary_diagnosis\",\n",
    "    \"Sample_ID\": \"Sample_ID\",  # TODO\n",
    "}\n",
    "tcga_annotation = tcga_annotation.rename(columns=columns_dict)\n",
    "\n",
    "# Standardize the 'Sex' column and convert 'Age' to numeric\n",
    "tcga_annotation[\"Sex\"] = tcga_annotation[\"Sex\"].replace(\n",
    "    {\"female\": \"Female\", \"male\": \"Male\"}\n",
    ")\n",
    "tcga_annotation[\"Age\"] = pd.to_numeric(tcga_annotation[\"Age\"], errors=\"coerce\")\n",
    "\n",
    "# Mark the samples that to be censored\n",
    "diag_to_censor_stat = {\n",
    "    \"Warty carcinoma\": 1,\n",
    "    \"Adenosquamous carcinoma\": 1,\n",
    "    \"Squamous cell carcinoma, keratinizing, NOS\": 0,\n",
    "    \"Papillary squamous cell carcinoma\": 1,\n",
    "    \"Squamous cell carcinoma, spindle cell\": 1,\n",
    "    \"Basaloid squamous cell carcinoma\": 1,\n",
    "    \"Squamous cell carcinoma, small cell, nonkeratinizing\": 1,\n",
    "    \"Squamous cell carcinoma, nonkeratinizing, NOS\": 0,\n",
    "    \"Lymphoepithelial carcinoma\": 1,\n",
    "    \"Squamous cell carcinoma, large cell, nonkeratinizing, NOS\": 1,\n",
    "    \"Papillary carcinoma, NOS\": 1,\n",
    "    \"Squamous cell carcinoma, NOS\": 0,\n",
    "}\n",
    "tcga_annotation[\"Censor\"] = tcga_annotation[\"Primary_diagnosis\"].map(\n",
    "    diag_to_censor_stat\n",
    ")\n",
    "\n",
    "# Condense the primary tumor site.\n",
    "nsclc_sites = {\n",
    "    \"Lower lobe, lung\",\n",
    "    \"Lung, NOS\",\n",
    "    \"Main bronchus\",\n",
    "    \"Middle lobe, lung\",\n",
    "    \"Overlapping lesion of lung\",\n",
    "    \"Upper lobe, lung\",\n",
    "}\n",
    "hnsq_sites = {\n",
    "    \"Anterior floor of mouth\",\n",
    "    \"Base of tongue, NOS\",\n",
    "    \"Border of tongue\",\n",
    "    \"Cheek mucosa\",\n",
    "    \"Floor of mouth, NOS\",\n",
    "    \"Gum, NOS\",\n",
    "    \"Hard palate\",\n",
    "    \"Head, face or neck, NOS\",\n",
    "    \"Hypopharynx, NOS\",\n",
    "    \"Larynx, NOS\",\n",
    "    \"Lip, NOS\",\n",
    "    \"Lower gum\",\n",
    "    \"Mandible\",\n",
    "    \"Mouth, NOS\",\n",
    "    \"Nasal cavity\",\n",
    "    \"Oropharynx, NOS\",\n",
    "    \"Overlapping lesion of lip, oral cavity and pharynx\",\n",
    "    \"Palate, NOS\",\n",
    "    \"Pharynx, NOS\",\n",
    "    \"Posterior wall of oropharynx\",\n",
    "    \"Retromolar area\",\n",
    "    \"Supraglottis\",\n",
    "    \"Tongue, NOS\",\n",
    "    \"Tonsil, NOS\",\n",
    "    \"Upper Gum\",\n",
    "    \"Ventral surface of tongue, NOS\",\n",
    "}\n",
    "cervix_sites = {\"Cervix uteri\"}\n",
    "eso_sites = {\n",
    "    \"Cardia, NOS\",\n",
    "    \"Esophagus, NOS\",\n",
    "    \"Lower third of esophagus\",\n",
    "    \"Middle third of esophagus\",\n",
    "    \"Thoracic esophagus\",\n",
    "    \"Upper third of esophagus\",\n",
    "}\n",
    "censor_sites = {\n",
    "    \"Breast, NOS\",\n",
    "    \"Bladder, NOS\",\n",
    "}\n",
    "\n",
    "tcga_annotation[\"Diagnosis\"] = None\n",
    "\n",
    "# Classify each row based on the tumor site\n",
    "for index, row in tcga_annotation.iterrows():\n",
    "    site = str(row[\"Tumor_site\"]).strip()\n",
    "    if site in cervix_sites:\n",
    "        tcga_annotation.loc[index, \"Diagnosis\"] = \"CERSQ_CA\"\n",
    "    elif site in nsclc_sites:\n",
    "        tcga_annotation.loc[index, \"Diagnosis\"] = \"NSCLC_SC\"\n",
    "    elif site in hnsq_sites:\n",
    "        tcga_annotation.loc[index, \"Diagnosis\"] = \"HNSQ_CA\"\n",
    "    elif site in eso_sites:\n",
    "        tcga_annotation.loc[index, \"Diagnosis\"] = \"ESO_CA_SQ\"\n",
    "    else:\n",
    "        tcga_annotation.loc[index, \"Censor\"] = 1\n",
    "        print(f\"Unmatched tumor site: {site} (index {index} - censored)\")\n",
    "\n",
    "# Removed censored samples\n",
    "tcga_annotation = tcga_annotation[tcga_annotation[\"Censor\"] == 0]\n",
    "\n",
    "# Extract useful columns\n",
    "tcga_annotation = tcga_annotation[columns_dict.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15d832a",
   "metadata": {},
   "source": [
    "### Step 2: Download and unzip the GEO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_anno_dir_tar = analysis_dir_scc / \"geo_annotations.tar.gz\"\n",
    "geo_anno_dir = geo_anno_dir_tar.with_suffix(\"\").with_suffix(\"\")\n",
    "\n",
    "# Check if the GEO annotation tar file exists and extract\n",
    "if not geo_anno_dir.exists():\n",
    "    print(\"Setting up GEO annotation directory...\")\n",
    "    # TODO download annotation\n",
    "    extract_tar(geo_anno_dir_tar, analysis_dir_scc)\n",
    "    print(\"Setting up GEO annotation directory done.\")\n",
    "\n",
    "# Download the IDAT files.\n",
    "download_from_geo_and_untar(analysis_dir_scc, datasets[tumor_site][\"geo_ids\"])\n",
    "\n",
    "\n",
    "# Download the annotation spreadsheet.\n",
    "def merge_csv(dir_path):\n",
    "    \"\"\"Reads all CSV files merges them.\"\"\"\n",
    "    dir_path = Path(dir_path)\n",
    "    merged_df = pd.DataFrame()\n",
    "    for csv_file in dir_path.glob(\"*.csv\"):\n",
    "        print(f\"Reading {csv_file}\")\n",
    "        data_frame = pd.read_csv(csv_file)\n",
    "        merged_df = pd.concat([merged_df, data_frame], ignore_index=True)\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "geo_annotation = merge_csv(geo_anno_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7b03a6",
   "metadata": {},
   "source": [
    "### Step 3: Construct the annotation file of all data.\n",
    "Join the TCGA and GEO annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69aacfb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if (csv_path := analysis_dir_scc / f\"{tumor_site}-annotation.csv\").exists():\n",
    "    print(\"Merged annotation file allready exists.\")\n",
    "else:\n",
    "    anno_df = pd.concat([geo_annotation, tcga_annotation], ignore_index=True)\n",
    "    anno_df.to_csv(csv_path, index=False)\n",
    "    print(\"Merged annotation file created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5bab9b",
   "metadata": {},
   "source": [
    "### Create the Methylation Analysis Object\n",
    "\n",
    "The `MethylAnalysis` object serves as the main interface for performing DNA\n",
    "methylation analysis. Key parameters such as the directory structure, number\n",
    "of CpG sites, and UMAP settings are configured here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_scc = MethylAnalysis(\n",
    "    analysis_dir=analysis_dir_scc,\n",
    "    reference_dir=reference_dir,\n",
    "    output_dir=output_dir,\n",
    "    test_dir=test_dir_scc,\n",
    "    n_cpgs=25000,\n",
    "    load_full_betas=True,\n",
    "    overlap=False,\n",
    "    cpg_blacklist=blacklist,\n",
    "    debug=True,\n",
    "    do_seg=True,\n",
    "    umap_parms={\n",
    "        \"n_neighbors\": 8,\n",
    "        \"metric\": \"manhattan\",\n",
    "        \"min_dist\": 0.3,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aaf7d6",
   "metadata": {},
   "source": [
    "### Load Beta Values\n",
    "\n",
    "Reads and processes beta values from the provided dataset. This step can also\n",
    "be performed interactively within the GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c224ab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "analysis_scc.set_betas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc1538",
   "metadata": {},
   "source": [
    "### Generate UMAP Plot\n",
    "\n",
    "Set the columns used for coloring the UMAP plot before initiating the\n",
    "dimensionality reduction process. The UMAP algorithm produces a visual\n",
    "representation of the sample clusters, which is stored as a Plotly object in\n",
    "`analysis_scc.umap_plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492a3085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate UMAP\n",
    "analysis_scc.idat_handler.selected_columns = [\"Diagnosis\"]\n",
    "analysis_scc.make_umap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbd19d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Show the results\n",
    "print(analysis_scc.umap_df)\n",
    "output_path = output_dir / f\"{analysis_dir_scc.name}-umap_plot.jpg\"\n",
    "analysis_scc.umap_plot.write_image(\n",
    "    output_path,\n",
    "    format=\"jpg\",\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    scale=2,\n",
    ")\n",
    "IPImage(filename=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb264b1",
   "metadata": {},
   "source": [
    "### Launch the Analysis GUI\n",
    "\n",
    "Initializes an interactive GUI for further exploration of the methylation\n",
    "data.\n",
    "\n",
    "**Note**: This step is only supported in local environments (not in\n",
    "cloud-based platforms like Google Colab or Binder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efde3a8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "analysis_scc.run_app(open_tab=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ad156",
   "metadata": {},
   "source": [
    "### Generate and Save CNV Plot\n",
    "\n",
    "Creates a copy number variation (CNV) plot for a specified sample and saves\n",
    "the output as a high-resolution image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b5ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CNV example\n",
    "analysis_scc.make_cnv_plot(\"364f7953-d0af-4929-8491-7b5e94d488aa_noid\")\n",
    "cnv_plot = analysis_scc.cnv_plot\n",
    "cnv_plot.update_layout(\n",
    "    yaxis_range=[-1.1, 1.1],\n",
    "    font={\"size\": FONTSIZE},\n",
    "    margin={\"t\": 50},\n",
    ")\n",
    "output_path = output_dir / f\"{analysis_dir_scc.name}-cnv_plot.jpg\"\n",
    "cnv_plot.write_image(\n",
    "    output_path,\n",
    "    format=\"jpg\",\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    scale=2,\n",
    ")\n",
    "IPImage(filename=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a00d2",
   "metadata": {},
   "source": [
    "### Generate CNV Summary Plots\n",
    "\n",
    "In addition to individual CNV plots, this step computes summary plots to\n",
    "highlight genomic alterations across multiple samples.\n",
    "\n",
    "**Note**:\n",
    "Generating all copy number variation (CNV) plots can be resource-intensive.\n",
    "The process may take up to 30 minutes, depending on the computational\n",
    "resources available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2437a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_scc.precompute_cnvs()\n",
    "cn_summary_path_scc = calculate_cn_summary(analysis_scc, \"Diagnosis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59891390",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPImage(filename=cn_summary_path_scc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca64ee",
   "metadata": {},
   "source": [
    "### Supervised Classifier Validation\n",
    "\n",
    "The next step involves validating various supervised classification\n",
    "algorithms to evaluate their performance on the dataset. This process helps\n",
    "identify the most accurate model for methylation-based classification.\n",
    "\n",
    "**Note**:\n",
    "Training can be resource-intensive. The process may take up to 10 minutes,\n",
    "depending on the computational resources available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c950446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train supervised classifiers\n",
    "ids = analysis_scc.idat_handler.ids\n",
    "clf_out_scc = analysis_scc.classify(\n",
    "    ids=ids,\n",
    "    clf_list=[\n",
    "        \"none-kbest-et\",\n",
    "        \"none-kbest-lr\",\n",
    "        \"none-kbest-rf\",\n",
    "        \"none-kbest-svc_rbf\",\n",
    "        \"none-pca-lr\",\n",
    "        \"none-pca-et\",\n",
    "        \"none-none-knn\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7921a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print reports for all classifier for the first sample\n",
    "for clf_result in clf_out_scc:\n",
    "    print(clf_result.reports[0])\n",
    "\n",
    "# Identify and display the best classifier\n",
    "best_clf_scc = max(\n",
    "    clf_out_scc, key=lambda result: np.mean(result.metrics[\"accuracy_scores\"])\n",
    ")\n",
    "print(\"Most accurate classifier:\")\n",
    "print(best_clf_scc.reports[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a6144c",
   "metadata": {},
   "source": [
    "# 4. Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc7490",
   "metadata": {},
   "source": [
    "The GEO annotation files were downloaded and manually curated. Below is the\n",
    "code used to download the GEO datasets and save their associated metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22abde44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T12:31:29.051272Z",
     "iopub.status.busy": "2024-12-20T12:31:29.051073Z",
     "iopub.status.idle": "2024-12-20T12:31:29.539461Z",
     "shell.execute_reply": "2024-12-20T12:31:29.538987Z",
     "shell.execute_reply.started": "2024-12-20T12:31:29.051260Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Requirement already satisfied: geoparse in /home/bruggerj/Projects/py3.12/lib/python3.12/site-packages (2.0.4)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/bruggerj/Projects/py3.12/lib/python3.12/site-packages (from geoparse) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.17 in /home/bruggerj/Projects/py3.12/lib/python3.12/site-packages (from geoparse) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/bruggerj/Projects/py3.12/lib/python3.12/site-packages (from geoparse) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /home/bruggerj/Projects/py3.12/lib/python3.12/site-packages (from geoparse) (4.66.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bruggerj/Projects/py3.12/lib/python3.12/site-packages (from pandas>=0.17->geoparse) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bruggerj/Projects/py3.12/lib/python3.12/site-packages (from pandas>=0.17->geoparse) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/bruggerj/Projects/py3.12/lib/python3.12/site-packages (from pandas>=0.17->geoparse) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bruggerj/Projects/py3.12/lib/python3.12/site-packages (from requests>=2.21.0->geoparse) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bruggerj/Projects/py3.12/lib/python3.12/site-packages (from requests>=2.21.0->geoparse) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bruggerj/Projects/py3.12/lib/python3.12/site-packages (from requests>=2.21.0->geoparse) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bruggerj/Projects/py3.12/lib/python3.12/site-packages (from requests>=2.21.0->geoparse) (2024.6.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/bruggerj/Projects/py3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=0.17->geoparse) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install geoparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e96d54",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import GEOparse\n",
    "import pandas as pd\n",
    "\n",
    "geo_numbers = datasets[\"scc\"][\"geo_ids\"] + datasets[\"scc_test\"][\"geo_ids\"]\n",
    "\n",
    "# Download and save metadata for each GEO series\n",
    "for geo_nr in geo_numbers:\n",
    "    gse = GEOparse.get_GEO(geo=geo_nr, destdir=geo_anno_dir)\n",
    "    metadata = gse.phenotype_data\n",
    "    print(metadata.head())\n",
    "    metadata.to_csv(geo_anno_dir / f\"{geo_nr}_raw_metadata.csv\", index=True)\n",
    "\n",
    "for file in geo_anno_dir.glob(\"*.soft.gz\"):\n",
    "    print(f\"Removing file: {file}\")\n",
    "    file.unlink()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
